# Audio Flamingo 2 CoT éƒ¨ç½²æŒ‡å—

æœ¬æ–‡æ¡£æä¾› Audio Flamingo 2 CoT æ¨¡å‹çš„å®Œæ•´éƒ¨ç½²å’Œä½¿ç”¨è¯´æ˜ã€‚

## ğŸ“‹ ç›®å½•ç»“æ„

```
/mnt/afs/haizhouli-folder/interspeech/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ flamingo_cot/              # æ¨¡å‹æƒé‡æ–‡ä»¶
â”‚   â””â”€â”€ flamingo_cot_bp/           # æºä»£ç 
â”‚       â””â”€â”€ af2/
â”‚           â””â”€â”€ inference_HF_pretrained/
â”œâ”€â”€ model_env/
â”‚   â””â”€â”€ flamingo_cot/              # Python è™šæ‹Ÿç¯å¢ƒ
â”œâ”€â”€ deployment/                     # éƒ¨ç½²è„šæœ¬ (æœ¬ç›®å½•)
â”‚   â”œâ”€â”€ setup_env.sh               # ç¯å¢ƒå®‰è£…è„šæœ¬
â”‚   â”œâ”€â”€ config.yaml                # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ inference_server.py        # æ¨ç†æœåŠ¡è„šæœ¬
â”‚   â”œâ”€â”€ test_deployment.sh         # æµ‹è¯•è„šæœ¬
â”‚   â””â”€â”€ README_DEPLOY.md           # æœ¬æ–‡æ¡£
â””â”€â”€ output/                         # è¾“å‡ºç›®å½• (è‡ªåŠ¨åˆ›å»º)
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ­¥éª¤ 1: å®‰è£…ç¯å¢ƒ

```bash
cd /mnt/afs/haizhouli-folder/interspeech/deployment
bash setup_env.sh
```

å®‰è£…æ—¶é—´çº¦ 10-15 åˆ†é’Ÿï¼Œæ ¹æ®ç½‘ç»œé€Ÿåº¦è€Œå®šã€‚

### æ­¥éª¤ 2: é…ç½® HuggingFace Token

1. è·å– HuggingFace Token:  https://huggingface.co/settings/tokens
2. ç¼–è¾‘é…ç½®æ–‡ä»¶: 

```bash
vi config.yaml
```

3. å°† `YOUR_HUGGINGFACE_TOKEN_HERE` æ›¿æ¢ä¸ºæ‚¨çš„å®é™… Token

**æˆ–è€…ç›´æ¥ä¿®æ”¹æ¨ç†è„šæœ¬:**

```bash
vi /mnt/afs/haizhouli-folder/interspeech/models/flamingo_cot_bp/af2/inference_HF_pretrained/inference. py
```

åœ¨ç¬¬ 183 è¡Œæ›¿æ¢æ‚¨çš„ Tokenã€‚

### æ­¥éª¤ 3: æµ‹è¯•éƒ¨ç½²

```bash
# æ¿€æ´»ç¯å¢ƒ
source /mnt/afs/haizhouli-folder/interspeech/model_env/flamingo_cot/bin/activate

# è¿è¡Œæµ‹è¯•
bash test_deployment.sh
```

## ğŸ“– ä½¿ç”¨æ–¹æ³•

### æ–¹æ³• 1: ç¯å¢ƒæ£€æŸ¥

```bash
source /mnt/afs/haizhouli-folder/interspeech/model_env/flamingo_cot/bin/activate
python inference_server.py --mode check
```

### æ–¹æ³• 2: å•ä¸ªéŸ³é¢‘æ¨ç†

```bash
source /mnt/afs/haizhouli-folder/interspeech/model_env/flamingo_cot/bin/activate

python inference_server.py \
    --mode single \
    --audio /path/to/your/audio.wav \
    --question "Describe the audio in detail."
```

### æ–¹æ³• 3: æ‰¹é‡æ¨ç†

1. å‡†å¤‡ JSONL æ–‡ä»¶ (æ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡):

```json
{"audio_path": "/path/to/audio1.wav", "question": "What sounds are in this audio?"}
{"audio_path": "/path/to/audio2.wav", "question": "Describe the music. "}
```

2. è¿è¡Œæ‰¹é‡æ¨ç†:

```bash
source /mnt/afs/haizhouli-folder/interspeech/model_env/flamingo_cot/bin/activate

python inference_server.py \
    --mode batch \
    --input your_questions.jsonl
```

### æ–¹æ³• 4: åˆ›å»ºç¤ºä¾‹æ–‡ä»¶

```bash
python inference_server.py --mode sample --output sample.jsonl
```

## ğŸ”§ é…ç½®è¯´æ˜

### config.yaml ä¸»è¦å‚æ•°

```yaml
model:
  repo_id: "nvidia/audio-flamingo-2"  # å¯é€‰ 3B/1. 5B/0.5B
  hf_token: "YOUR_TOKEN"

inference:
  temperature: 0.0      # 0.0=ç¡®å®šæ€§, 0.7-1.0=åˆ›é€ æ€§
  top_k:  50
  top_p:  0.95
  max_new_tokens: 512

hardware:
  device: "cuda"
  gpu_id: 0
  precision: "fp16"     # æˆ– "fp32"
```

### æ¨¡å‹ç‰ˆæœ¬é€‰æ‹©

| æ¨¡å‹ | å‚æ•°é‡ | HuggingFace ID | æ€§èƒ½ |
|------|--------|----------------|------|
| é»˜è®¤ | 3B | nvidia/audio-flamingo-2 | æœ€ä½³ |
| ä¸­ç­‰ | 1.5B | nvidia/audio-flamingo-2-1.5B | è‰¯å¥½ |
| å°å‹ | 0.5B | nvidia/audio-flamingo-2-0.5B | å¿«é€Ÿ |

## ğŸ“ JSONL æ–‡ä»¶æ ¼å¼

```json
{"audio_path": "/absolute/path/to/audio.wav", "question": "Your question here"}
```

**è¦æ±‚:**
- ä½¿ç”¨ç»å¯¹è·¯å¾„
- æ”¯æŒæ ¼å¼:  WAV, MP3, FLAC
- æœ€å¤§æ—¶é•¿: 5 åˆ†é’Ÿ
- æ¯è¡Œä¸€ä¸ªå®Œæ•´çš„ JSON å¯¹è±¡

## ğŸ¯ ç¤ºä¾‹é—®é¢˜

### é€šç”¨ç†è§£
- "Describe the audio in detail."
- "What sounds can you hear?"
- "Summarize this audio clip."

### éŸ³ä¹åˆ†æ
- "What is the genre of this music?"
- "Describe the instruments used."
- "What is the mood of this music?"

### è¯­éŸ³åˆ†æ
- "What is the speaker's emotion?"
- "How many speakers are there?"
- "What is being discussed?"

### ç¯å¢ƒéŸ³
- "Where was this audio recorded?"
- "What activities are happening?"
- "Describe the acoustic environment."

## âš™ï¸ é«˜çº§ç”¨æ³•

### ç›´æ¥ä½¿ç”¨åŸå§‹æ¨ç†è„šæœ¬

```bash
cd /mnt/afs/haizhouli-folder/interspeech/models/flamingo_cot_bp/af2/inference_HF_pretrained

source /mnt/afs/haizhouli-folder/interspeech/model_env/flamingo_cot/bin/activate

# ç¼–è¾‘ inference.jsonl
vi inference.jsonl

# è¿è¡Œæ¨ç†
python inference.py --input inference.jsonl
```

### ä¿®æ”¹é‡‡æ ·å‚æ•°

ç¼–è¾‘ `inference.py` ç¬¬ 232 è¡Œ: 

```python
# ç¡®å®šæ€§è¾“å‡º (ç”¨äºåŸºå‡†æµ‹è¯•)
temperature=0.0, do_sample=False

# æˆ–åˆ›é€ æ€§è¾“å‡º (ç”¨äºå¯¹è¯)
temperature=0.8, top_k=50, top_p=0.95, do_sample=True
```

### åˆ‡æ¢æ¨¡å‹ç‰ˆæœ¬

ç¼–è¾‘ `inference.py` ç¬¬ 183 è¡Œå’Œ `configs/inference.yaml` ç¬¬ 81-82 è¡Œ:

**0.5B æ¨¡å‹:**
```python
# inference.py L183
repo_id="nvidia/audio-flamingo-2-0.5B"

# configs/inference.yaml L81-82
lm_path:  Qwen/Qwen2.5-0.5B
lm_tokenizer_path: Qwen/Qwen2.5-0.5B
```

**1.5B æ¨¡å‹:**
```python
# inference.py L183
repo_id="nvidia/audio-flamingo-2-1.5B"

# configs/inference.yaml L81-82
lm_path: Qwen/Qwen2.5-1.5B
lm_tokenizer_path: Qwen/Qwen2.5-1.5B
```

## ğŸ› å¸¸è§é—®é¢˜

### 1. CUDA Out of Memory

**è§£å†³æ–¹æ¡ˆ:**
- åˆ‡æ¢åˆ°è¾ƒå°çš„æ¨¡å‹ (1.5B æˆ– 0.5B)
- å‡å°‘éŸ³é¢‘æ—¶é•¿
- ä½¿ç”¨ `precision: "fp32"` å¦‚æœ fp16 æœ‰é—®é¢˜

### 2. HuggingFace Token é”™è¯¯

**é”™è¯¯ä¿¡æ¯:** `401 Unauthorized`

**è§£å†³æ–¹æ¡ˆ:**
- ç¡®è®¤ Token æœ‰æ•ˆ:  https://huggingface.co/settings/tokens
- ç¡®è®¤æœ‰æ¨¡å‹è®¿é—®æƒé™
- ä¿®æ”¹ `inference.py` ç¬¬ 183 è¡Œ

### 3. éŸ³é¢‘æ–‡ä»¶æ‰¾ä¸åˆ°

**è§£å†³æ–¹æ¡ˆ:**
- ä½¿ç”¨ç»å¯¹è·¯å¾„
- æ£€æŸ¥æ–‡ä»¶æƒé™
- ç¡®è®¤éŸ³é¢‘æ ¼å¼ (WAV/MP3/FLAC)

### 4. æ¨¡å—å¯¼å…¥é”™è¯¯

**è§£å†³æ–¹æ¡ˆ:**
```bash
# é‡æ–°æ¿€æ´»ç¯å¢ƒ
source /mnt/afs/haizhouli-folder/interspeech/model_env/flamingo_cot/bin/activate

# æ£€æŸ¥å®‰è£…
pip list | grep torch
pip list | grep transformers
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### H100 GPU ä¼˜åŒ–è®¾ç½®

æ‚¨çš„ H100 80GB éå¸¸å¼ºå¤§ï¼Œå»ºè®®: 

```yaml
hardware:
  precision: "fp16"  # ä½¿ç”¨æ··åˆç²¾åº¦
  
inference:
  # å¯ä»¥å¤„ç†æ›´é•¿çš„éŸ³é¢‘
  max_audio_duration: 300  # 5åˆ†é’Ÿ
  max_new_tokens: 1024     # æ›´é•¿çš„å›ç­”
```

### æ‰¹é‡å¤„ç†ä¼˜åŒ–

å¯¹äºå¤§é‡éŸ³é¢‘æ–‡ä»¶: 

```bash
# å¹¶è¡Œå¤„ç†å¤šä¸ª GPU (å¦‚æœæœ‰å¤šå¼ å¡)
CUDA_VISIBLE_DEVICES=0 python inference. py --input batch1.jsonl &
CUDA_VISIBLE_DEVICES=1 python inference.py --input batch2.jsonl &
```

## ğŸ“š å‚è€ƒèµ„æ–™

- **è®ºæ–‡:** https://arxiv.org/abs/2503.03983
- **é¡¹ç›®ä¸»é¡µ:** https://github.com/NVIDIA/audio-flamingo
- **Demo:** https://research.nvidia.com/labs/adlr/AF2/
- **HuggingFace:** https://huggingface.co/nvidia/audio-flamingo-2

## ğŸ“„ è®¸å¯è¯

- **ä»£ç :** MIT License
- **æ¨¡å‹:** NVIDIA OneWay Noncommercial License (ä»…ä¾›éå•†ä¸šç ”ç©¶ä½¿ç”¨)
- **ä¾èµ–:** Qwen Research License, OpenAI Terms of Use

## ğŸ’¡ æŠ€æœ¯æ”¯æŒ

å¦‚é‡åˆ°é—®é¢˜: 

1. æ£€æŸ¥ç¯å¢ƒ:  `python inference_server.py --mode check`
2. æŸ¥çœ‹æ—¥å¿—è¾“å‡º
3. å‚è€ƒå®˜æ–¹æ–‡æ¡£:  https://github.com/NVIDIA/audio-flamingo

---

**éƒ¨ç½²è„šæœ¬ä½œè€…:** GitHub Copilot  
**åˆ›å»ºæ—¥æœŸ:** 2026-01-01  
**ç‰ˆæœ¬:** 1.0

